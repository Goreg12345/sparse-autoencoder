{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-07T08:39:00.113601Z",
     "start_time": "2024-03-07T08:39:00.074641Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "import torch.utils.data\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '0'\n",
    "sys.path.append(\"sae_visualizer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81a67a890612a03e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-07T08:39:18.800739Z",
     "start_time": "2024-03-07T08:39:18.781186Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/tmp/pycharm_project_349/ioi_subspaces')\n",
    "sys.path.append('/tmp/pycharm_project_451')\n",
    "from new_codebase import Circuit\n",
    "from load_sae import load_head_sae, is_available\n",
    "\n",
    "\n",
    "c = Circuit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e744855",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_name_mover_sae(c):\n",
    "    ioi_nodes = [c.heads[head].zs['end'] for head, head_data in c.heads.items() if head_data.head_class=='nm']\n",
    "\n",
    "    saes = {}\n",
    "    for node in ioi_nodes:\n",
    "        if is_available(node):\n",
    "            print(node)\n",
    "            component, layer, head = node.component_name, node.layer, node.head\n",
    "            saes[node] = load_head_sae(layer, head, component, perform_sanity_check=False)\n",
    "            # turn off gradients\n",
    "            saes[node].requires_grad_(False)\n",
    "    return ioi_nodes, saes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c12f1fbb6cc1ce3c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-05T00:19:21.547880100Z",
     "start_time": "2024-03-05T00:19:21.537059500Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_saes(c):\n",
    "    saes = {}\n",
    "    ioi_nodes = []\n",
    "    for node in c.nodes:\n",
    "        if is_available(node, project_name='sae-all-ioi-heads'):\n",
    "            print(node)\n",
    "            component, layer, head = node.component_name, node.layer, node.head\n",
    "            sae = load_head_sae(layer, head, component, perform_sanity_check=False, project_name='sae-all-ioi-heads')\n",
    "            if sae.cfg['d_hidden'] != 1000:\n",
    "                ioi_nodes.append(node)\n",
    "                saes[node] = sae\n",
    "                # turn off gradients\n",
    "                saes[node].requires_grad_(False)\n",
    "    return ioi_nodes, saes\n",
    "ioi_nodes, saes = load_saes(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebb91127eba638e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-07T06:55:56.995780Z",
     "start_time": "2024-03-07T06:55:54.616308Z"
    }
   },
   "outputs": [],
   "source": [
    "from transformer_lens import HookedTransformer\n",
    "\n",
    "model = HookedTransformer.from_pretrained('gpt2-small', device='cuda')\n",
    "model.requires_grad_(False)\n",
    "print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48cca198",
   "metadata": {},
   "source": [
    "# Load IOI dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a1998c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ioi_utils import PromptDataset, PromptDistribution, NAMES, PLACES, OBJECTS, PREFIXES, TEMPLATES\n",
    "\n",
    "\n",
    "def sample_ioi(model, prompt_distribution, patterns, samples_per_combination: int):\n",
    "    prompts = []\n",
    "    for pattern in patterns:\n",
    "        for _ in range(samples_per_combination):\n",
    "            prompts.append(prompt_distribution.sample_one(pattern, model))\n",
    "    dataset = PromptDataset(prompts, model)\n",
    "    return dataset\n",
    "\n",
    "\n",
    "ioi_distribution = PromptDistribution(\n",
    "    prefix_len=2,\n",
    "    templates=TEMPLATES[:2],\n",
    "    names=NAMES,\n",
    "    places=PLACES,\n",
    "    objects=OBJECTS,\n",
    "    prefixes=PREFIXES\n",
    ")\n",
    "\n",
    "ioi_dataset = sample_ioi(model, ioi_distribution, ['ABB', 'BAB'], 10000)\n",
    "batch_sampler = torch.utils.data.BatchSampler(\n",
    "    torch.utils.data.SequentialSampler(ioi_dataset),\n",
    "    batch_size=10,\n",
    "    drop_last=False,\n",
    ")\n",
    "ioi_loader = torch.utils.data.DataLoader(\n",
    "    ioi_dataset,\n",
    "    sampler=batch_sampler,\n",
    "    batch_size=None,\n",
    ")\n",
    "\n",
    "# for test set, we need the same names etc, just different combinations\n",
    "ioi_test_dataset = sample_ioi(model, ioi_distribution, ['ABB', 'BAB'], 10000)\n",
    "batch_sampler = torch.utils.data.BatchSampler(\n",
    "    torch.utils.data.SequentialSampler(ioi_test_dataset),\n",
    "    batch_size=10,\n",
    "    drop_last=False,\n",
    ")\n",
    "ioi_test_loader = torch.utils.data.DataLoader(\n",
    "    ioi_test_dataset,\n",
    "    sampler=batch_sampler,\n",
    "    batch_size=None,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16558fe0",
   "metadata": {},
   "source": [
    "# Calculate alive and ioi features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d09ff171038aa1a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-07T06:55:49.413309Z",
     "start_time": "2024-03-07T06:55:49.384412Z"
    }
   },
   "outputs": [],
   "source": [
    "from autoscoring import get_alive_neurons\n",
    "from IPython.display import clear_output\n",
    "\n",
    "\n",
    "n_alive = {}\n",
    "features_alive = {}\n",
    "for node, encoder in saes.items():\n",
    "    idx_alive = get_alive_neurons(encoder, model)\n",
    "    n_alive[node] = idx_alive.numel()\n",
    "    features_alive[node] = idx_alive\n",
    "clear_output()\n",
    "n_alive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d39bd6f7d720393",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-07T05:49:06.620753Z",
     "start_time": "2024-03-07T05:49:06.615545Z"
    }
   },
   "outputs": [],
   "source": [
    "# save features_alive\n",
    "import pickle\n",
    "\n",
    "with open('../data/features_alive.pkl', 'wb') as f:\n",
    "    pickle.dump(features_alive, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd65a38731099af9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-07T06:56:01.762742Z",
     "start_time": "2024-03-07T06:56:01.754261Z"
    }
   },
   "outputs": [],
   "source": [
    "# load features_alive\n",
    "import pickle\n",
    "\n",
    "with open('../data/features_alive.pkl', 'rb') as f:\n",
    "    features_alive = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2b913f26b1b044c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-07T05:52:14.874850Z",
     "start_time": "2024-03-07T05:49:38.850951Z"
    }
   },
   "outputs": [],
   "source": [
    "from autoscoring import get_ioi_neurons\n",
    "n_ioi = {}\n",
    "ioi_neurons_idx = {}\n",
    "for node, encoder in saes.items():\n",
    "    idx_alive = get_ioi_neurons(encoder, model, ioi_loader, node, max_batches=1000)\n",
    "    n_ioi[node] = idx_alive.numel()\n",
    "    ioi_neurons_idx[node] = idx_alive\n",
    "n_ioi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26147bad53c0b70e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-07T06:39:34.949040Z",
     "start_time": "2024-03-07T06:39:34.921597Z"
    }
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('../data/ioi_neurons_idx.pkl', 'wb') as f:\n",
    "    pickle.dump(ioi_neurons_idx, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58976aaf0d9681a0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-07T06:56:48.954425Z",
     "start_time": "2024-03-07T06:56:48.924166Z"
    }
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('../data/ioi_neurons_idx.pkl', 'rb') as f:\n",
    "    ioi_neurons_idx = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4da7224398cdd8a4",
   "metadata": {},
   "source": [
    "# Extract feature activations and count them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdb27d6733b579b8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-07T06:41:50.673183Z",
     "start_time": "2024-03-07T06:39:40.154884Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from tqdm import tqdm\n",
    "from research.autoscoring import run_with_cache, LabeledTensor\n",
    "\n",
    "\n",
    "measures = ['count', 'sum', 'total', ]\n",
    "patterns = ['ABB', 'BAB']\n",
    "roles = ['s', 'io']\n",
    "num_neurons = max([saes[node].cfg['d_hidden'] for node in ioi_nodes])\n",
    "shape = (len(measures), len(ioi_nodes), len(patterns), len(roles), len(NAMES), num_neurons)\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def get_actv_counts(model, ioi_loader, saes, ioi_nodes, shape):\n",
    "    actv_counts = LabeledTensor(shape, measures=measures, ioi_nodes=ioi_nodes, patterns=patterns, \n",
    "                            roles=roles, names=NAMES, device='cpu')\n",
    "    for batch in tqdm(ioi_loader):\n",
    "        cache = run_with_cache(model, batch, ioi_nodes)\n",
    "        for i, node in enumerate(ioi_nodes):\n",
    "            actvs = cache[i]  # (batch, neurons)\n",
    "            feature_actvs = saes[node].encoder(actvs)\n",
    "            is_active = feature_actvs > 0\n",
    "            for j, prompt in enumerate(batch.prompts):\n",
    "                p = prompt.pattern\n",
    "                s = prompt.s_name\n",
    "                io = prompt.io_name\n",
    "                \n",
    "                # Count\n",
    "                actv_counts['count', node, p, 's', s] += is_active[j].int().cpu()\n",
    "                actv_counts['count', node, p, 'io', io] += is_active[j].int().cpu()\n",
    "                \n",
    "                # Sum\n",
    "                actv_counts['sum', node, p, 's', s] += feature_actvs[j].cpu()\n",
    "                actv_counts['sum', node, p, 'io', io] += feature_actvs[j].cpu()\n",
    "                \n",
    "                # Total\n",
    "                actv_counts['total', node, p, 's', s] += 1\n",
    "                actv_counts['total', node, p, 'io', io] += 1\n",
    "\n",
    "    return actv_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5952deeccf55ef2f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-07T06:41:50.799956Z",
     "start_time": "2024-03-07T06:41:50.680977Z"
    }
   },
   "outputs": [],
   "source": [
    "actv_counts = get_actv_counts(model, ioi_loader, saes, ioi_nodes, shape)\n",
    "test_actv_counts = get_actv_counts(model, ioi_test_loader, saes, ioi_nodes, shape)\n",
    "\n",
    "actv_counts.save('../data/feature_actvs.pt')\n",
    "test_actv_counts.save('../data/test_feature_actvs.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9fdf21a6b7a6446",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-07T06:58:26.663769Z",
     "start_time": "2024-03-07T06:58:26.611476Z"
    }
   },
   "outputs": [],
   "source": [
    "actv_counts = LabeledTensor.load('../data/feature_actvs.pt')\n",
    "test_actv_counts = LabeledTensor.load('../data/test_feature_actvs.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc21c590f94f299a",
   "metadata": {},
   "source": [
    "# Feature Scoring based on activation counts\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bf5c50f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from research.autoscoring import get_genders\n",
    "\n",
    "\n",
    "is_male = get_genders(NAMES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4610b108",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "ioi_components = pd.DataFrame(columns=['component', 'layer', 'head', 'id', 'seq_pos', 'node'])\n",
    "for node in ioi_nodes:\n",
    "    component = node.component_name\n",
    "    layer = node.layer\n",
    "    head = node.head\n",
    "    id = f'({component}, {layer}, {head})'\n",
    "    seq_pos = node.seq_pos\n",
    "    ioi_components.loc[len(ioi_components)] = {'component': component, 'layer': layer, 'head': head, 'id': id, 'seq_pos': seq_pos, 'node': node}\n",
    "ioi_components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2698d983",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from research.autoscoring import io_name_score, s_name_score, contains_name_score, first_name_score, second_name_score, name_x_pos, gender_x_role_score, name_score, io_pos_score, gender_score, context_position_score, name_x_context_pos_score\n",
    "\n",
    "\n",
    "tqdm.pandas()\n",
    "\n",
    "\n",
    "# these feature types are only well-defined over s2 and end nodes\n",
    "# you can't calculate them on io or s1 nodes because their sequence position isn't fixed which is an assumption that these functions make\n",
    "name_feature_types = {\n",
    "    'io_name': io_name_score,\n",
    "    's_name': s_name_score,\n",
    "    'contains_name': contains_name_score,\n",
    "    'first_name': first_name_score,\n",
    "    'second_name': second_name_score,\n",
    "    'first_name_S': partial(name_x_pos, pattern='BAB', role='s'),\n",
    "    'second_name_IO': partial(name_x_pos, pattern='BAB', role='io'),\n",
    "    'first_name_IO': partial(name_x_pos, pattern='ABB', role='io'),\n",
    "    'second_name_S': partial(name_x_pos, pattern='ABB', role='s'),\n",
    "    's_is_male': partial(gender_x_role_score, role='s', gender='M', is_male=is_male),\n",
    "    's_is_female': partial(gender_x_role_score, role='s', gender='F', is_male=is_male),\n",
    "    'io_is_male': partial(gender_x_role_score, role='io', gender='M', is_male=is_male),\n",
    "    'io_is_female': partial(gender_x_role_score, role='io', gender='F', is_male=is_male),\n",
    "\n",
    "}\n",
    "\n",
    "def describe_features(df):\n",
    "    num_neurons = max([saes[node].cfg['d_hidden'] for node in ioi_nodes])\n",
    "    feature_descriptions = []\n",
    "    id = df['id'].iloc[0]\n",
    "    for feature_id in range(num_neurons):\n",
    "        for _, row in df[df.seq_pos.isin(['s2', 'end'])].iterrows():\n",
    "            node = row['node']\n",
    "\n",
    "            # DEAD NEURONS\n",
    "            if feature_id not in features_alive[node]:\n",
    "                row = {'node': node, 'feature_id': feature_id, 'feature_type': 'dead', 'topk': 0, 'names': '', \n",
    "                    'recall': 0, 'precision': 0, 'f_score': 0, 'component': id}\n",
    "                feature_descriptions.append(row)\n",
    "\n",
    "            # NEURONS THAT NEVER FIRE ON IOI PROMPTS\n",
    "            elif feature_id not in ioi_neurons_idx[node]:\n",
    "                row = {'node': node, 'feature_id': feature_id, 'feature_type': 'not_ioi', 'topk': 0, 'names': '',\n",
    "                    'recall': 0, 'precision': 0, 'f_score': 0, 'component': id}\n",
    "                feature_descriptions.append(row)\n",
    "            else:\n",
    "                # FEATURES ON S2 AND END NODES\n",
    "                for feature_type, func in name_feature_types.items():\n",
    "                    scores = func(actv_counts[:, node, :, :, :, feature_id], test_actv_counts=test_actv_counts[:, node, :, :, :, feature_id])\n",
    "                    scores['node'] = node\n",
    "                    scores['feature_id'] = feature_id\n",
    "                    scores['feature_type'] = feature_type\n",
    "                    scores['component'] = id\n",
    "                    feature_descriptions.append(scores)\n",
    "\n",
    "                for pattern in patterns:\n",
    "                    # select the number of activations at the io position\n",
    "                    score = io_pos_score(actv_counts[:, node, :, :, :, feature_id], pattern, test_actv_counts=test_actv_counts[:, node, :, :, :, feature_id])\n",
    "                    score['node'] = node\n",
    "                    score['feature_id'] = feature_id\n",
    "                    score['component'] = id\n",
    "                    feature_descriptions.append(score)\n",
    "\n",
    "                for role in roles:\n",
    "                    for gender in ['M', 'F']:\n",
    "                        score = gender_x_role_score(actv_counts[:, node, :, :, :, feature_id], role, gender, is_male=is_male, test_actv_counts=test_actv_counts[:, node, :, :, :, feature_id])\n",
    "                        score['node'] = node\n",
    "                        score['feature_id'] = feature_id\n",
    "                        score['component'] = id\n",
    "                        feature_descriptions.append(score)\n",
    "\n",
    "        # FEATURES ON IO AND S1 NODES\n",
    "        if df.seq_pos.str.contains('io').any():\n",
    "            io_node = df.loc[df.seq_pos == 'io', 'node'].iloc[0]\n",
    "            s_node = df.loc[df.seq_pos == 's1', 'node'].iloc[0]\n",
    "            score = name_score(actv_counts[:, :, :, :, :, feature_id], io_node, s_node, test_actv_counts=test_actv_counts[:, :, :, :, :, feature_id])\n",
    "            score['node'] = io_node\n",
    "            score['feature_id'] = feature_id\n",
    "            score['feature_type'] = 'current_name'\n",
    "            score['component'] = id\n",
    "            feature_descriptions.append(score)\n",
    "\n",
    "            for gender in ['M', 'F']:\n",
    "                score = gender_score(actv_counts[:, :, :, :, :, feature_id], io_node, s_node, gender, is_male, test_actv_counts=test_actv_counts[:, :, :, :, :, feature_id])\n",
    "                score['node'] = io_node\n",
    "                score['feature_id'] = feature_id\n",
    "                score['component'] = id\n",
    "                feature_descriptions.append(score)\n",
    "\n",
    "            for position in [1, 2]:\n",
    "                score = context_position_score(actv_counts[:, :, :, :, :, feature_id], io_node, s_node, position, test_actv_counts=test_actv_counts[:, :, :, :, :, feature_id])\n",
    "                score['node'] = io_node\n",
    "                score['feature_id'] = feature_id\n",
    "                score['component'] = id\n",
    "                feature_descriptions.append(score)\n",
    "\n",
    "                score = name_x_context_pos_score(actv_counts[:, :, :, :, :, feature_id], io_node, s_node, position, test_actv_counts=test_actv_counts[:, :, :, :, :, feature_id])\n",
    "                score['node'] = io_node\n",
    "                score['feature_id'] = feature_id\n",
    "                score['feature_type'] = f'current_name_pos_{position}'\n",
    "                score['component'] = id\n",
    "                feature_descriptions.append(score)\n",
    "    df = pd.DataFrame(feature_descriptions)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afc431b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# without parallelization\n",
    "df = ioi_components.groupby('id').progress_apply(describe_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f159b7ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each SAE neuron, accept the feature with the best training f_score\n",
    "final_df = df.groupby(['node', 'feature_id']).apply(lambda df: df.loc[df.f_score.idxmax()])\n",
    "final_df.to_csv('../data/feature_descriptions.csv')\n",
    "final_df[final_df.f_score > 0.75]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b9aa108",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary\n",
    "for node in ioi_nodes:\n",
    "    print(node)\n",
    "    for feature_type in final_df.feature_type.unique():\n",
    "        print(feature_type, len(final_df[(final_df.feature_type == feature_type) & (final_df.f_score > 0.4) & (final_df.node == node)]))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78b2fe2d",
   "metadata": {},
   "source": [
    "# Random Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5f75ade",
   "metadata": {},
   "outputs": [],
   "source": [
    "melt = pd.melt(final_df.reset_index(drop=True), id_vars=['node', 'feature_id', 'feature_type', 'topk', 'names'], \n",
    "        value_vars=['recall', 'precision', 'f_score'],\n",
    "        value_name='value', var_name='metric')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dbc38ff",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "sns.displot(data=melt[melt['value'] > 0.], x='value', col='metric', hue='node', bins=100, \n",
    "            alpha=0.2, kind='hist', col_wrap=3, legend=False, facet_kws={'sharex': False, 'sharey': False})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e7be715",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(final_df[final_df.feature_type=='first_name_S'], x='topk', hue='node', bins=30)\n",
    "import matplotlib.pyplot as plt\n",
    "plt.xlabel('Number of names in the IO name feature')\n",
    "plt.title('IO name features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1d6cf2083fa0bf6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "98a00c35",
   "metadata": {},
   "source": [
    "# This implementation is nice and readable but fucking slow\n",
    "\n",
    "Due to how pandas accesses multilevel index values. It's currently being fixed, e.g. https://github.com/pandas-dev/pandas/issues/38650"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25b324151dffff78",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "measure = pd.Categorical(['count', 'sum', 'total'], ordered=True)\n",
    "pattern = pd.Categorical(['ABB', 'BAB'], ordered=True)\n",
    "role = pd.Categorical(['s', 'io'])\n",
    "multi_index = pd.MultiIndex.from_product([measure, pd.Categorical(ioi_nodes), pattern, role, pd.Categorical(NAMES), np.arange(saes[ioi_nodes[0]].cfg['d_hidden'])], names=['measure', 'node', 'pattern', 'role', 'name', 'neuron'])\n",
    "df = pd.DataFrame(0, index=multi_index, columns=['data'])\n",
    "df.info()\n",
    "from tqdm import tqdm\n",
    "from research.autoscoring import run_with_cache\n",
    "\n",
    "\n",
    "for batch in tqdm(ioi_loader):\n",
    "    cache = run_with_cache(model, batch, ioi_nodes)\n",
    "    for i, node in enumerate(ioi_nodes):\n",
    "        actvs = cache[i]  # (batch, neurons)\n",
    "        feature_actvs = saes[node].encoder(actvs)\n",
    "        is_active = feature_actvs > 0\n",
    "        # this is slow because we can't batch it but the code is much more readable by using pandas\n",
    "        for j, prompt in enumerate(batch.prompts):                \n",
    "            df.loc[('count', node, prompt.pattern, 's', [prompt.s_name]), 'data'] += is_active[j].int().cpu().numpy()\n",
    "            df.loc[('count', node, prompt.pattern, 'io', [prompt.io_name]), 'data'] += is_active[j].int().cpu().numpy()\n",
    "            df.loc[('sum', node, prompt.pattern, 's', [prompt.s_name]), 'data'] += feature_actvs[j].cpu().numpy()\n",
    "            df.loc[('sum', node, prompt.pattern, 'io', [prompt.io_name]), 'data'] += feature_actvs[j].cpu().numpy()\n",
    "            df.loc[('total', node, prompt.pattern, 's', [prompt.s_name]), 'data'] += 1\n",
    "            df.loc[('total', node, prompt.pattern, 'io', [prompt.io_name]), 'data'] += 1        \n",
    "df[df.data>0]\n",
    "# normalize the dataframe: divide sum by total and divide count by total, then remove total\n",
    "df = df.unstack(level='measure')\n",
    "df['sum'] = df[('data', 'count')] / df[('data', 'total')]\n",
    "df['count'] = df[('data', 'count')] / df[('data', 'total')]\n",
    "df = df.drop(columns='data')\n",
    "df.head()\n",
    "feature_types = pd.Categorical(['io_name', 's_name'], ordered=True)\n",
    "feature_idx = np.arange(saes[ioi_nodes[0]].cfg['d_hidden'])\n",
    "multi_index = pd.MultiIndex.from_product([pd.Categorical(ioi_nodes), feature_types, pd.Categorical(NAMES), feature_idx], names=['node', 'feature_type', 'name', 'feature_idx'])\n",
    "feature_scores = pd.DataFrame(0, index=multi_index, columns=['score'])\n",
    "feature_scores = feature_scores.sort_index(level=['node', 'feature_type', 'name', 'feature_idx'])\n",
    "feature_scores\n",
    "for node in ioi_nodes:\n",
    "    for name in tqdm(NAMES):\n",
    "        io_scores_abb = df.loc[(node, 'ABB', 'io', name, feature_idx), 'count'].to_numpy()\n",
    "        io_scores_bab = df.loc[(node, 'BAB', 'io', name, feature_idx), 'count'].to_numpy()\n",
    "        s_scores_aba = df.loc[(node, 'ABB', 's', name, feature_idx), 'count'].to_numpy()\n",
    "        s_scores_baa = df.loc[(node, 'BAB', 's', name, feature_idx), 'count'].to_numpy()\n",
    "        score = io_scores_bab * io_scores_abb - (s_scores_aba + s_scores_baa)\n",
    "        feature_scores.loc[(node, 'io_name', name, feature_idx), 'score'] = score\n",
    "        feature_scores.loc[(node, 's_name', name, feature_idx), 'score'] = s_scores_aba * s_scores_baa - (io_scores_bab + io_scores_abb)\n",
    "feature_scores.to_csv('../data/feature_scores.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
